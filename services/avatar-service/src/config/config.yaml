# LLM Configuration
llm:
  default_model: gemma3
  server_url: "http://localhost:8000"
  endpoints:
    prompt: "/ollama/prompt"
    health_check: "/ollama"

# Default Prompts
prompts:
  default_admin: |
    You are a Japanese teacher having conversation with a Japanese learner. 
    Always respond in natural, polite Japanese.
    Do not explain your respond in English or use any romaji even if you are asked in English.
    No emoji (😊), emoticons (_), kaomoji (＞＜), or symbols except standard punctuation (。、「」). 
    Every answer must follow this rule.
  default_user: "こんにちは、元気ですか？"

# Voicevox engine
tts:
  onnxruntime_path: "./voicevox/python/onnxruntime/lib/libvoicevox_onnxruntime.so.1.17.3"
  synthesizer_path: "./voicevox/python/dict/open_jtalk_dic_utf_8-1.11"
  vvm_folder_path: "./voicevox/python/models/vvms"
  wav_output_path: "output.wav"
  acceleration_mode: "AUTO"
  cpu_num_threads: 4

# UI Configuration
ui:
  title: Nihongo Companion
  header: "# 🎌 Nihongo Companion - AI Japanese Tutor"
  instruction: |
    ## 📝 How to Use This Interface

    1. **Model Name**: Enter the AI model you want to use (default: gemma3)
    2. **User Prompt**: Type your message or question in Japanese or English
    3. **Admin Prompt**: (Optional) Provide context like "You are a Japanese tutor" to guide the AI's response
    4. **Voice Actor & Style**: Choose the voice characteristics for the audio output
    5. **Click Submit**: The AI will generate both text and audio responses automatically

    **Example**: Try asking "こんにちは、元気ですか？" (Hello, how are you?) with admin prompt "You are a friendly Japanese conversation partner."
  share: false
  auto_launch: true

# Imported from LiveTalking

# Audio Settings
audio:
  fps: 50  # audio fps, must be 50
  sample_rate: 16000  # audio sample rate

# Sliding Window Settings (unit: 20ms)
sliding_window:
  left: 10   # -l parameter
  middle: 8  # -m parameter  
  right: 10  # -r parameter

# GUI Settings
gui:
  width: 450   # GUI width
  height: 450  # GUI height

# Avatar Settings
avatar:
  id: "avator_1"  # define which avatar in data/avatars
  batch_size: 16  # infer batch size

# Custom Video Configuration
custom:
  video_config: ""  # path to custom action json file

# Transport Settings
transport:
  type: "rtcpush"  # transport type: webrtc, rtcpush, virtualcam
  push_url: "http://localhost:1985/rtc/v1/whip/?app=live&stream=livestream"

# Server Settings
server:
  max_sessions: 1      # maximum concurrent sessions
  listen_port: 8010    # web server listen port
  host: "0.0.0.0"      # server host address

# Model Paths
model_paths:
  wav2lip: "./models/wav2lip.pth"

# Avatar Paths
avatar_paths:
  base_dir: "./data/avatars"